{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "VwFZRxEgyBTL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provides stability in model training (prevents exploding/vanishing gradients problem). Prevents internal covarinat shift."
      ],
      "metadata": {
        "id": "GaJM0I_F7unE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SnE4fLzawAo-"
      },
      "outputs": [],
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self, emd_dim):\n",
        "      super().__init__()\n",
        "      self.scale = nn.Parameter(torch.ones(emd_dim))\n",
        "      self.shift = nn.Parameter(torch.zeros(emd_dim))\n",
        "      self.eps = 1e-5\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1,keepdim=True)\n",
        "    var = x.var(dim=-1,keepdim=True, unbiased=False)\n",
        "    norm_x = (x-mean)/torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2,5)\n",
        "layer = nn.Sequential(nn.Linear(5,6),nn.ReLU())\n",
        "output = layer(batch_example)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n11bmONIx_Au",
        "outputId": "805ab64f-1240-4a90-ec48-d840b8df9c0a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ln = LayerNormalization(5)\n",
        "normalized = ln.forward(batch_example)\n",
        "normalized.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejx-LxUOyoDZ",
        "outputId": "c4ce7f8f-1df3-4049-b29e-f58e26da3639"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-4.7684e-08, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evp3wxGey6B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differentiable at 0. Solves dead neuron problem. x*phi(x) phi(x)~ CDF of standard normal distribution.\n",
        "\n",
        "Gaussian Error Linear Unit"
      ],
      "metadata": {
        "id": "MXlC6KDEQu9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "  def forward(self,x):\n",
        "      return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3))))\n",
        "\n"
      ],
      "metadata": {
        "id": "HqzACYCXPjeS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'Emb_dim' : 768\n",
        "}"
      ],
      "metadata": {
        "id": "y3BL8YdfWrdc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "   def __init__(self,CFG):\n",
        "      super().__init__()\n",
        "      self.layers = nn.Sequential(\n",
        "          nn.Linear(CFG['Emb_dim'],4*CFG['Emb_dim']), #expansion\n",
        "          GELU(), # gelu\n",
        "          nn.Linear(4*CFG['Emb_dim'],CFG['Emb_dim']) #contraction\n",
        "      )\n",
        "\n",
        "   def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "zdoUX6QyRVz8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffn = FeedForward(CFG)\n",
        "x = torch.rand((2,3,768))\n",
        "op=ffn.forward(x)\n",
        "print(op.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H59sQy8nXHlC",
        "outputId": "8836fbf0-2f96-4435-822a-d7885cfff6f6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3d_Q24IXeTB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}