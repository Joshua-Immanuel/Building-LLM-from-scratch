{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4x9GFM0xGOky"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2cvua0tyd8n",
        "outputId": "4a135381-bbf0-4475-ed83-9b7ebd2fe1cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "sAs8Kx0wlGlq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "kI4GfLULlMps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT2_124M_CFG={\n",
        "    'dropout':0.1,\n",
        "    'n_layers':12,\n",
        "    'n_heads':12,\n",
        "    'emb_size':768,\n",
        "    'context_length':1024,\n",
        "    'vocab_size':50257,\n",
        "    'qkv_bias':False\n",
        "}"
      ],
      "metadata": {
        "id": "V_XuWosyia1D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self,emb_size):\n",
        "       super().__init__()\n",
        "       self.scale = nn.Parameter(torch.ones(emb_size))\n",
        "       self.shift = nn.Parameter(torch.ones(emb_size))\n",
        "       self.eps = 1e-5\n",
        "\n",
        "  def forward(self,x):\n",
        "      mean = torch.mean(x,dim=-1,keepdim=True)\n",
        "      var = torch.var(x,dim=-1,keepdim=True,unbiased=False)\n",
        "      return self.scale* (x-mean)/torch.sqrt(var+self.eps) + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg['emb_size'],4*cfg['emb_size']),\n",
        "        GELU(),\n",
        "        nn.Linear(4*cfg['emb_size'],cfg['emb_size'])\n",
        "    )\n",
        "  def forward(self,x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "JDvcGvxHGiT2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self,din,dout,n_heads,context_length,dropout,qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.w_queries = nn.Linear(din,dout,qkv_bias)\n",
        "        self.w_keys = nn.Linear(din,dout,qkv_bias)\n",
        "        self.w_values = nn.Linear(din,dout,qkv_bias)\n",
        "        self.register_buffer('mask',torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
        "        self.out_layer = nn.Linear(dout,dout)\n",
        "        self.n_heads= n_heads\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch, context_length, emb_size = x.shape\n",
        "    queries = self.w_queries(x)\n",
        "    keys = self.w_keys(x)\n",
        "    values = self.w_values(x)\n",
        "    head_dim = emb_size//self.n_heads\n",
        "\n",
        "    queries = queries.view(batch,context_length,self.n_heads,head_dim)\n",
        "    keys = keys.view(batch,context_length,self.n_heads,head_dim)\n",
        "    values = values.view(batch,context_length,self.n_heads,head_dim)\n",
        "     # b,cl,nheads,hd.\n",
        "\n",
        "\n",
        "     # b, nheads, cl, hd\n",
        "    queries = queries.transpose(1,2)\n",
        "    keys = keys.transpose(1,2)\n",
        "    values = values.transpose(1,2)\n",
        "\n",
        "    attention_scores = queries @ keys.transpose(2,3)\n",
        "       #b, nheads, cl,cl\n",
        "\n",
        "    attention_scores.masked_fill_(self.mask.bool()[:context_length,:context_length],-torch.inf)\n",
        "\n",
        "    attention_weights = torch.softmax(attention_scores/(keys.shape[-1])**0.5, dim =-1)\n",
        "    attention_weights = self.dropout(attention_weights)\n",
        "    context_vectors = (attention_weights @ values).transpose(1,2)\n",
        "    # b, nheads,cl,cl.     b,nheads, cl, hd\n",
        "    # b, nheads, cl,hd.     .T -> b, cl,nheads,hd\n",
        "    context_vectors = context_vectors.contiguous().view(batch, context_length, emb_size)\n",
        "    context_vectors = self.out_layer(context_vectors)\n",
        "    return context_vectors\n"
      ],
      "metadata": {
        "id": "8DnJu2gKacdu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.dropout = nn.Dropout(cfg['dropout'])\n",
        "    self.norm1 = LayerNormalization(cfg['emb_size'])\n",
        "    self.norm2 = LayerNormalization(cfg['emb_size'])\n",
        "    self.att = MultiheadAttention(\n",
        "        din = cfg['emb_size'],\n",
        "        dout = cfg['emb_size'],\n",
        "        n_heads=cfg['n_heads'],\n",
        "        context_length = cfg['context_length'],\n",
        "        dropout = cfg['dropout'],\n",
        "        qkv_bias=cfg['qkv_bias'])\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x= self.att(x)\n",
        "    x= self.dropout(x)\n",
        "    x= shortcut+x\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x= self.ff(x)\n",
        "    x= self.dropout(x)\n",
        "    x= shortcut+x\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "ibjRx_PtgRFu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['emb_size'])\n",
        "    self.pos_emb = nn.Embedding(cfg['context_length'],cfg['emb_size'])\n",
        "    self.out_head = nn.Linear(cfg['emb_size'],cfg['vocab_size'],bias=False)\n",
        "    self.drop_emb = nn.Dropout(cfg['dropout'])\n",
        "    self.blocks = nn.Sequential(\n",
        "        *[Transformer(cfg) for _ in range(cfg['n_layers'])]\n",
        "    )\n",
        "    self.final_norm = LayerNormalization(cfg['emb_size'])\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch, n_tokens = x.shape\n",
        "    token_embed = self.tok_emb(x)\n",
        "    position_embed = self.pos_emb(torch.arange(n_tokens,device=x.device))\n",
        "    x =  token_embed + position_embed\n",
        "    x= self.drop_emb(x)\n",
        "    x= self.blocks(x)\n",
        "    x= self.final_norm(x)\n",
        "    logits= self.out_head(x)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "ccagkS76jFSs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_simple(idx,model,max_words,context_length):\n",
        "  model.eval()\n",
        "  for _ in range(max_words):\n",
        "   idx_new = idx[:,-context_length:]\n",
        "   with torch.no_grad():\n",
        "    logits = model(idx_new)\n",
        "   temp = logits[:,-1,:]\n",
        "   temp= torch.softmax(temp,dim=-1)\n",
        "   next = torch.argmax(temp,dim=-1,keepdim=True)\n",
        "   idx = torch.cat((idx,next),dim=-1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "x2daSTKksiMZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\""
      ],
      "metadata": {
        "id": "oXj3N_NnWy6D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(idx,context_length,model,max_words,temperature=0.0,top_k=None,end_token=None):\n",
        "  model.eval()\n",
        "  for _ in range(max_words):\n",
        "      new_idx = idx[:,-context_length:]\n",
        "      with torch.no_grad():\n",
        "        logits = model(new_idx)\n",
        "      logits = logits[:,-1,:]\n",
        "\n",
        "     # temperature scaling + topk sampling\n",
        "      if top_k is not None:\n",
        "          top_logits,_ = torch.topk(logits,top_k)\n",
        "          min_val = top_logits[:,-1].unsqueeze(-1)\n",
        "          logits = torch.where(logits<min_val,torch.tensor(float(\"-inf\")).to(logits.device),logits)\n",
        "      if temperature>0.0:\n",
        "          logits = logits/temperature\n",
        "          probas = torch.softmax(logits,dim=-1)\n",
        "          next = torch.multinomial(probas,num_samples=1)\n",
        "      else:\n",
        "        logits = torch.softmax(logits,dim=-1)\n",
        "        next = torch.argmax(logits,dim=-1,keepdim=True)\n",
        "      if next==end_token:\n",
        "          break\n",
        "      idx = torch.cat((idx,next),dim=-1)\n",
        "  return idx\n"
      ],
      "metadata": {
        "id": "pB3uhRHYgOIo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tswqWxHob0U3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import ssl\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Create an unverified SSL context\n",
        "    ssl_context = ssl._create_unverified_context()\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBTVz9s2b0hV",
        "outputId": "edcddfae-afae-4fb0-aef4-692a6686cd21"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path,sep='\\t',header=None, names=['Label','Text'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CXKKPASRcWGL",
        "outputId": "cd4418ef-895b-4e28-a295-c0ebb8771fcb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec509865-ca1a-459f-b437-1a8f266e3aad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec509865-ca1a-459f-b437-1a8f266e3aad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec509865-ca1a-459f-b437-1a8f266e3aad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec509865-ca1a-459f-b437-1a8f266e3aad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c77145cc-0924-45ee-ba43-f0b07ae7079e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c77145cc-0924-45ee-ba43-f0b07ae7079e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c77145cc-0924-45ee-ba43-f0b07ae7079e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_64344440-a782-4f71-a074-01987d1ad53f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_64344440-a782-4f71-a074-01987d1ad53f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "xNolZq3BcsAG",
        "outputId": "e347458c-e922-4729-9bc5-1ac4803345fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "ham     4825\n",
              "spam     747\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>4825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsRjVsVDdMZP",
        "outputId": "b9cad302-4c2a-4194-c127-9380973de14a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "x0acNyUkdazg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n"
      ],
      "metadata": {
        "id": "-uo6Uz3rdoRP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df))\n",
        "print(len(validation_df))\n",
        "print(len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCHKf6qZdzLN",
        "outputId": "3cf44380-7143-4759-cc60-8eb050d411d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1045\n",
            "149\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "LD1EXNZPd1v0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class spamDataset(Dataset):\n",
        "  def __init__(self, csv_file, tokenizer, max_length=None, pad_id = 50256):\n",
        "      self.data = pd.read_csv(csv_file)\n",
        "      self.encoded_texts = [\n",
        "          tokenizer.encode(text) for text in self.data['Text']\n",
        "      ]\n",
        "      if max_length is None:\n",
        "        self.max_length = max([len(tokens) for tokens in self.encoded_texts])\n",
        "      else:\n",
        "        self.max_length = max_length\n",
        "        self.encoded_texts = [\n",
        "          tokens[:self.max_length] for tokens in self.encoded_texts\n",
        "        ]\n",
        "      self.encoded_texts = [encoded_txt + [pad_id]*(self.max_length-len(encoded_txt)) for encoded_txt in self.encoded_texts]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "     encoded = self.encoded_texts[index]\n",
        "     label = self.data['Label'][index]\n",
        "     return (\n",
        "             torch.tensor(encoded,dtype=torch.long),\n",
        "             torch.tensor(label,dtype=torch.long)\n",
        "            )\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        ""
      ],
      "metadata": {
        "id": "k-mm4b_seL3X"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = spamDataset('train.csv',tokenizer)\n",
        "train_dataset.max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUTL9xoFkV4r",
        "outputId": "b712a541-51dd-467c-cebb-668c8f0eda78"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = spamDataset('test.csv',tokenizer,max_length=train_dataset.max_length)\n",
        "test_dataset.max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5trHfHsIpWH0",
        "outputId": "e66a15fd-4d8d-4489-d38d-046161f7b5e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = spamDataset('validation.csv',tokenizer,max_length=train_dataset.max_length)\n",
        "val_dataset.max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At12oKNephjG",
        "outputId": "d5c96195-d885-4436-d424-ada123e2f184"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "FcQIkIWAqR_h"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_dataloader:\n",
        "      pass\n",
        "print(input_batch.shape)\n",
        "print(target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBTAStzsrXG3",
        "outputId": "98e2ca23-b8c1-4a8f-ea9d-cb57b6d7735f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 120])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader),\" # of batches\")\n",
        "print(len(test_dataloader),\" # of batches\")\n",
        "print(len(validation_dataloader),\" # of batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjlqPFbvrct9",
        "outputId": "a0140c79-1b52-435f-919b-2f510518271a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130  # of batches\n",
            "37  # of batches\n",
            "18  # of batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL =\"(gpt2-small 124M)\"\n",
        "input_promt =\"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG ={\n",
        "    'dropout':0.0,\n",
        "    'n_layers':12,\n",
        "    'n_heads':12,\n",
        "    'emb_size':768,\n",
        "    'context_length':1024,\n",
        "    'vocab_size':50257,\n",
        "    'qkv_bias':True\n",
        "}\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG['context_length'],(\n",
        "    f\"the dataset exceeds models context length\"\n",
        ")"
      ],
      "metadata": {
        "id": "FX0Mm5WLslsZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "setting, params = download_and_load_gpt2(model_size='124M',models_dir=\"gpt2\")\n",
        "\n",
        "gpt = GPT2(cfg=BASE_CONFIG)\n",
        "gpt.eval();\n",
        "\n",
        "def assign(left,right):\n",
        "  if left.shape != right.shape:\n",
        "    raise ValueError(\"shape mismatch\")\n",
        "  return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLVQlQEV7OPT",
        "outputId": "33b1769b-c5f3-4738-a577-acbf94614d8f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_weights_into_gpt(gpt,params):\n",
        "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "\n",
        "  for b in range(len(params['blocks'])):\n",
        "\n",
        "        q_w, k_w, v_w = np.split(params['blocks'][b]['attn']['c_attn']['w'],3,axis=-1)\n",
        "        gpt.blocks[b].att.w_queries.weight = assign(gpt.blocks[b].att.w_queries.weight,q_w.T)\n",
        "        gpt.blocks[b].att.w_keys.weight = assign(gpt.blocks[b].att.w_keys.weight,k_w.T)\n",
        "        gpt.blocks[b].att.w_values.weight = assign(gpt.blocks[b].att.w_values.weight,v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(params['blocks'][b]['attn']['c_attn']['b'],3,axis=-1)\n",
        "        gpt.blocks[b].att.w_queries.bias = assign(gpt.blocks[b].att.w_queries.bias,q_b)\n",
        "        gpt.blocks[b].att.w_keys.bias = assign(gpt.blocks[b].att.w_keys.bias,k_b)\n",
        "        gpt.blocks[b].att.w_values.bias = assign(gpt.blocks[b].att.w_values.bias,v_b)\n",
        "\n",
        "        gpt.blocks[b].att.out_layer.weight = assign(gpt.blocks[b].att.out_layer.weight, params['blocks'][b]['attn']['c_proj']['w'].T)\n",
        "        gpt.blocks[b].att.out_layer.bias = assign(gpt.blocks[b].att.out_layer.bias, params['blocks'][b]['attn']['c_proj']['b'])\n",
        "\n",
        "        gpt.blocks[b].ff.layers[0].weight = assign(gpt.blocks[b].ff.layers[0].weight, params['blocks'][b]['mlp']['c_fc']['w'].T)\n",
        "        gpt.blocks[b].ff.layers[0].bias = assign(gpt.blocks[b].ff.layers[0].bias, params['blocks'][b]['mlp']['c_fc']['b'])\n",
        "        gpt.blocks[b].ff.layers[2].weight = assign(gpt.blocks[b].ff.layers[2].weight, params['blocks'][b]['mlp']['c_proj']['w'].T)\n",
        "        gpt.blocks[b].ff.layers[2].bias = assign(gpt.blocks[b].ff.layers[2].bias, params['blocks'][b]['mlp']['c_proj']['b'])\n",
        "\n",
        "\n",
        "        gpt.blocks[b].norm1.scale = assign(gpt.blocks[b].norm1.scale, params['blocks'][b]['ln_1']['g'])\n",
        "        gpt.blocks[b].norm1.shift = assign(gpt.blocks[b].norm1.shift, params['blocks'][b]['ln_1']['b'])\n",
        "\n",
        "        gpt.blocks[b].norm2.scale = assign(gpt.blocks[b].norm2.scale, params['blocks'][b]['ln_2']['g'])\n",
        "        gpt.blocks[b].norm2.shift = assign(gpt.blocks[b].norm2.shift, params['blocks'][b]['ln_2']['b'])\n",
        "\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale,params['g'])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift,params['b'])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params['wte'])"
      ],
      "metadata": {
        "id": "80hAHeMo71yi"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt,params)\n",
        "gpt.to(device);"
      ],
      "metadata": {
        "id": "Z93aeqtN72pL"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "                     idx = text_to_token_ids(\"Every effort moves you\",tokenizer).to(device),\n",
        "                     context_length=1024,\n",
        "                     model=gpt,\n",
        "                     max_words = 20,\n",
        "                     temperature=1.5,top_k=50,end_token=None\n",
        "                     )"
      ],
      "metadata": {
        "id": "e2imsXYD75q9"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids_to_text(token_ids,tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9bC_XNH58AA7",
        "outputId": "8dd2d30b-3d38-4289-9aba-18251e8e8b31"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 =(\"Is the following text spam? Answer with 'yes' or 'no'\"\n",
        "        \"'You are a winner you have been specially selected to received $1000 cash or $2000 award.\")\n",
        "token_ids = generate(\n",
        "                     idx = text_to_token_ids(text2,tokenizer).to(device),\n",
        "                     context_length=1024,\n",
        "                     model=gpt,\n",
        "                     max_words = 50,\n",
        "                     temperature=1.5,top_k=50,end_token=None\n",
        "                     )"
      ],
      "metadata": {
        "id": "rxP70AjnAUNS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids_to_text(token_ids,tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "lFLnQ17RBLdA",
        "outputId": "a86a6985-40c2-47c6-ef83-a4e35531bfe3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is the following text spam? Answer with \\'yes\\' or \\'no\\'\\'You are a winner you have been specially selected to received $1000 cash or $2000 award.You can view any form that you received by selecting a form number: \"Cash Card Card\" (3D) - PayPal Credit CARD or IDI Online: [FBA]\\n\\n\\nMoney Order\\n\\n\\n1 Credit Card/ IDI card ('"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = 2"
      ],
      "metadata": {
        "id": "J8Do0i4tY6IX"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in gpt.parameters():\n",
        "  params.requires_grad=False"
      ],
      "metadata": {
        "id": "JsBkClC5BNQ4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.out_head = nn.Linear(BASE_CONFIG['emb_size'],num_class)"
      ],
      "metadata": {
        "id": "bbJVahDvY0jE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in gpt.final_norm.parameters():\n",
        "   params.requires_grad=True"
      ],
      "metadata": {
        "id": "XQHViLsjYtsW"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in gpt.blocks[-1].parameters():\n",
        "   params.requires_grad=True"
      ],
      "metadata": {
        "id": "lDBFoKExZb8-"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = text_to_token_ids(\"do you have time\",tokenizer).to(device)\n",
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpdg6XbRZuZY",
        "outputId": "54ffea20-d350-4a43-fc8f-8dd4715daf7b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.to(device);"
      ],
      "metadata": {
        "id": "K18HaJtfxSz3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  output = gpt(inputs)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rKP03IHaPEI",
        "outputId": "652eff1f-32f0-46d8-b185-ccc55b98f730"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRFQ6uR9acrQ",
        "outputId": "fc2924b4-00f9-45f1-b76d-add0dc1816a0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.4661, -0.2504],\n",
              "         [10.3746, -3.1089],\n",
              "         [ 8.9922, -1.8229],\n",
              "         [ 5.2944, -1.0763]]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8b49WNksb2U"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader,model,device,num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions , num_examples =0,0\n",
        "\n",
        "    if num_batches is  None:\n",
        "      num_batches = len(data_loader)\n",
        "    else:\n",
        "      num_batches = min( len(data_loader),num_batches)\n",
        "\n",
        "    for i,(input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i< num_batches:\n",
        "          input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "          with torch.no_grad():\n",
        "            output = model(input_batch)[:,-1,:]\n",
        "          pred_labels = torch.argmax(output,dim=-1)\n",
        "          num_examples += pred_labels.shape[0]\n",
        "          correct_predictions += (pred_labels == target_batch).sum().item()\n",
        "        else:\n",
        "          break\n",
        "    return correct_predictions/num_examples"
      ],
      "metadata": {
        "id": "oRr6walBr3DH"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "3xikPLBGtvvO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.to(device)\n",
        "train_acc = calc_accuracy_loader(train_dataloader,gpt,device,num_batches=10)\n",
        "val_acc = calc_accuracy_loader(validation_dataloader,gpt,device,num_batches=10)\n",
        "test_acc = calc_accuracy_loader(test_dataloader,gpt,device,num_batches=10)\n",
        "\n",
        "print(\"the train accuracy is :\",train_acc*100)\n",
        "print(\"the validation accuracy is :\",val_acc*100)\n",
        "print(\"the test accuracy is :\",test_acc*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKEjBPCmuoCX",
        "outputId": "dad32e69-c05d-461f-d601-755b13a74336"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the train accuracy is : 47.5\n",
            "the validation accuracy is : 42.5\n",
            "the test accuracy is : 55.00000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(model,input_batch,target_batch,device):\n",
        "   input_batch,target_batch =  input_batch.to(device),target_batch.to(device)\n",
        "   logits = model(input_batch)[:,-1,:]\n",
        "   loss = nn.functional.cross_entropy(logits,target_batch)\n",
        "   return loss"
      ],
      "metadata": {
        "id": "NR_Inb6vvURV"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "\n",
        "    if  len(data_loader) == 0:\n",
        "      return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "      num_batches = len(data_loader)\n",
        "    else:\n",
        "      num_batches = min( len(data_loader),num_batches)\n",
        "\n",
        "    for i,(input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i< num_batches:\n",
        "          input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "          loss = calc_loss_batch(model, input_batch, target_batch, device)\n",
        "          total_loss += loss.item()\n",
        "        else:\n",
        "          break\n",
        "    return total_loss/num_batches"
      ],
      "metadata": {
        "id": "MqZoBY5tyjDD"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.to(device)\n",
        "train_loss = calc_loss_loader(train_dataloader,gpt,device,num_batches=10)\n",
        "val_loss = calc_loss_loader(validation_dataloader,gpt,device,num_batches=10)\n",
        "test_loss = calc_loss_loader(test_dataloader,gpt,device,num_batches=10)\n",
        "\n",
        "print(\"the train loss is :\",train_loss)\n",
        "print(\"the validation loss is :\",val_loss)\n",
        "print(\"the test loss is :\",test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCg-XzEdzuwj",
        "outputId": "a6d10226-09c6-45c1-fb63-160220b02b7b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the train loss is : 2.5197812795639036\n",
            "the validation loss is : 2.3361956238746644\n",
            "the test loss is : 2.8181297421455382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning model on supervised data"
      ],
      "metadata": {
        "id": "X1O5elI9CUKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "xYeFQYD7GbuP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter):\n",
        "  train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "  example_seen, global_step = 0 ,1\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(model,input_batch,target_batch,device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      example_seen += input_batch.shape[0]\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step% eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"epoch:{epoch+1} step:{global_step}. train_loss:{train_loss}. val_loss:{val_loss}\")\n",
        "    train_accuracy = calc_accuracy_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "    val_accuracy= calc_accuracy_loader(val_loader,model,device,num_batches=eval_iter)\n",
        "    print(\"training accurcay:\",train_accuracy)\n",
        "    print(\"validation accuracy:\",val_accuracy)\n",
        "    train_accs.append(train_accuracy)\n",
        "    val_accs.append(val_accuracy)\n",
        "  return train_losses, val_losses, train_accs, val_accs"
      ],
      "metadata": {
        "id": "mXMp7AiTz0i6"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(gpt.parameters(),lr=5e-5,weight_decay=0.1)\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs= train_classifier_simple(gpt,train_dataloader,\n",
        "                                                                        validation_dataloader,optimizer,device,\n",
        "                                                                        num_epochs=5,eval_freq=50,eval_iter=5)\n",
        "end_time = time.time()\n",
        "print(\"total time taken:\",(end_time-start_time)/60,\"min\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v745-Q_eHZQ3",
        "outputId": "0bc123d4-188c-4070-889c-c4ec17ed9b2a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1 step:50. train_loss:0.13297739587724208. val_loss:0.0415451155975461\n",
            "epoch:1 step:100. train_loss:0.0384824201464653. val_loss:0.0463905394077301\n",
            "training accurcay: 1.0\n",
            "validation accuracy: 0.975\n",
            "epoch:2 step:150. train_loss:0.09851536089554429. val_loss:0.05158086847513914\n",
            "epoch:2 step:200. train_loss:0.017506040912121535. val_loss:0.10436288760975003\n",
            "epoch:2 step:250. train_loss:0.018467493914067747. val_loss:0.20461810659617186\n",
            "training accurcay: 0.925\n",
            "validation accuracy: 0.975\n",
            "epoch:3 step:300. train_loss:0.029174886597320437. val_loss:0.09178385958075523\n",
            "epoch:3 step:350. train_loss:0.05620777998119593. val_loss:0.0359452607226558\n",
            "training accurcay: 0.95\n",
            "validation accuracy: 0.975\n",
            "epoch:4 step:400. train_loss:0.15595321580767632. val_loss:0.02922084084711969\n",
            "epoch:4 step:450. train_loss:0.18419695184566082. val_loss:0.009554243134334683\n",
            "epoch:4 step:500. train_loss:0.015533103747293353. val_loss:0.16502193324267864\n",
            "training accurcay: 1.0\n",
            "validation accuracy: 0.975\n",
            "epoch:5 step:550. train_loss:0.09942157277837396. val_loss:0.05736545597901568\n",
            "epoch:5 step:600. train_loss:0.13936488397885113. val_loss:0.009250814467668534\n",
            "epoch:5 step:650. train_loss:0.00536076370626688. val_loss:0.0351428807945922\n",
            "training accurcay: 1.0\n",
            "validation accuracy: 0.975\n",
            "total time taken: 37.33179150422414 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = calc_accuracy_loader(train_dataloader,gpt,device)\n",
        "val_acc = calc_accuracy_loader(validation_dataloader,gpt,device)\n",
        "test_acc = calc_accuracy_loader(test_dataloader,gpt,device)\n",
        "\n",
        "print(\"the train accuracy is :\",train_acc*100)\n",
        "print(\"the validation accuracy is :\",val_acc*100)\n",
        "print(\"the test accuracy is :\",test_acc*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d4NxoUQLhnE",
        "outputId": "f874f6b6-93de-4274-f9b7-fb54eae29fb8"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the train accuracy is : 98.46153846153847\n",
            "the validation accuracy is : 98.61111111111111\n",
            "the test accuracy is : 96.28378378378379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(model,text,tokenizer,max_length,device,padding_id=50256):\n",
        "  model.eval()\n",
        "  token_ids = tokenizer.encode(text)\n",
        "  token_ids = token_ids[:min(max_length,model.pos_emb.weight.shape[0])]\n",
        "\n",
        "  token_ids += [padding_id]*(max_length-len(token_ids))\n",
        "  token_ids = torch.tensor(token_ids,device=device).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    output = model(token_ids)[:,-1,:]\n",
        "  predicted_label =torch.argmax(output,dim=-1).item()\n",
        "\n",
        "  return \"spam\" if predicted_label == 1 else \"no spam\"\n",
        ""
      ],
      "metadata": {
        "id": "hz2N9frlP-aZ"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "You are a winner you have been specially selected to received $1000 cash or $2000 award.\n",
        "\"\"\"\n",
        "print(classify_review(gpt,text,tokenizer,max_length=train_dataset.max_length,device=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkivhAJLXdAo",
        "outputId": "fa452af2-0cb8-4b6e-ec53-d1ab658628b1"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Hi dinner money lottery give me cash\n",
        "\"\"\"\n",
        "print(classify_review(gpt,text,tokenizer,max_length=train_dataset.max_length,device=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU-bZ0RQaSo2",
        "outputId": "2023ef44-4938-4452-fd9d-4137d02403de"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gpt.state_dict(),'spam_classifier.pth')"
      ],
      "metadata": {
        "id": "5c24qKLrawHY"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_state_dict = torch.load('spam_classifier.pth')\n",
        "gpt.load_state_dict(gpt_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X563mS8mbJc1",
        "outputId": "1b23cfde-abb3-4ead-8dba-39839d1190df"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Dear Friend,\n",
        "\n",
        "Are you tired of working a 9 to 5 job? Want to become your own boss and make thousands of dollars from home? This is your chance! Our proven system has helped people just like you to earn money more quickly and easily than they ever imagined.\n",
        "\n",
        "Just visit our website and sign up to start making money today: [Insert Link Here]\n",
        "\n",
        "Don't wait, this opportunity won't last long!\n",
        "\"\"\"\n",
        "print(classify_review(gpt,text,tokenizer,max_length=train_dataset.max_length,device=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL6yfdjWbsI4",
        "outputId": "771c9db6-c8d1-4a74-e075-c40e2d30ebae"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2nlePgwcHHx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}